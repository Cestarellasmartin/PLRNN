{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "662b040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import Libraries\n",
    "#This is a test\n",
    "import os\n",
    "import pickle\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as tc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "from bptt.models import Model\n",
    "import model_anafunctions as func\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c3de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% FUNCTIONS\n",
    "def Hyper_mod(mpath,data_path):\n",
    "    file=open(os.path.join(mpath,'hypers.pkl').replace(\"\\\\\",\"/\"),'rb')\n",
    "    hyper=pickle.load(file)\n",
    "    file.close()\n",
    "    hyper['data_path']=os.path.join(data_path,'Training_data.npy').replace('\\\\','/')\n",
    "    hyper['inputs_path']=os.path.join(data_path,'Training_inputs.npy').replace('\\\\','/')\n",
    "    hyper['device_id'] = 0\n",
    "    full_name = open(os.path.join(mpath,'hypers.pkl').replace(\"\\\\\",\"/\"),\"wb\")                      # Name for training data\n",
    "    pickle.dump(hyper,full_name)            # Save train data\n",
    "    #close save instance \n",
    "    full_name.close()\n",
    "\n",
    "def Classifier_events(X_data,X_dataT,X_model,X_modelT,Event,Trainexp,Testexp):\n",
    "    # Train classifier with training data\n",
    "    ND_train = Event[Trainexp]\n",
    "    ND_test = Event[Testexp]\n",
    "\n",
    "    #%% Next Decisions\n",
    "    score_data=[]\n",
    "    score_model=[]\n",
    "    score_modelSh=[]\n",
    "    score_dataSh=[]\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    for i in range(1000):\n",
    "        # Classifying data\n",
    "        X_train=X_data\n",
    "        y_train=ND_train\n",
    "        X_test = X_dataT\n",
    "        y_test = ND_test\n",
    "        clf.fit(X_train,y_train)\n",
    "        score_data.append(clf.score(X_test,y_test))\n",
    "\n",
    "        # Classifying data Shuffle\n",
    "        list_trials=np.linspace(0,X_data.shape[0]-1,X_data.shape[0]).astype(int)\n",
    "        np.random.shuffle(list_trials)\n",
    "        y=ND_train[list_trials]\n",
    "        random_state=0\n",
    "        X_trainS, X_testS, y_trainS, y_testS = train_test_split(\n",
    "            X_train, y, test_size=0.2, stratify=y, random_state=0\n",
    "            )\n",
    "        clf.fit(X_trainS,y_trainS)\n",
    "        score_dataSh.append(clf.score(X_testS,y_testS))\n",
    "\n",
    "        # Classifying model\n",
    "        X_trainM=X_model\n",
    "        y_trainM=ND_train\n",
    "        X_testM = X_modelT\n",
    "        y_testM = ND_test\n",
    "        clf.fit(X_trainM,y_trainM)\n",
    "        score_model.append(clf.score(X_testM,y_testM))\n",
    "        \n",
    "        # Classifying model Shuffle\n",
    "        list_trials=np.linspace(0,X_data.shape[0]-1,X_data.shape[0]).astype(int)\n",
    "        np.random.shuffle(list_trials)\n",
    "        y=ND_train[list_trials]\n",
    "        X_trainMS, X_testMS, y_trainMS, y_testMS = train_test_split(\n",
    "            X_trainM, y, test_size=0.2, stratify=y, random_state=0\n",
    "            )\n",
    "        clf.fit(X_trainMS,y_trainMS)\n",
    "        score_modelSh.append(clf.score(X_testMS,y_testMS))\n",
    "\n",
    "    return np.array(score_data).mean(),np.array(score_dataSh).mean(),np.array(score_model).mean(),np.array(score_modelSh).mean()\n",
    "\n",
    "\n",
    "def Plot_trace_example(Neuron_data,Model_data,Input_data,eneu): \n",
    "    ################################ Parameters to modify ################################ \n",
    "    # Plot properties\n",
    "    # colors\n",
    "    c_recorded_activity = 'black'                                   # Color for line: Recorded Activity \n",
    "    c_simulated_activity = 'red'                                    # Color for line: Simulated Activity\n",
    "    c_stop = '#C13E71'                                              # Color for area: Wheel stop phase\n",
    "    c_cue = '#71C13E'                                               # Color for area: Response phase\n",
    "    c_gamble = '#3E71C1'                                            # Color for area: Gamble reward\n",
    "    c_safe = '#C18E3E'                                              # Color for area: Safe reward\n",
    "    alpha_value = 0.2                                               # Transparency level for sections of the trial (stop wheel, cue, reward g/s)\n",
    "    #####################################################################################\n",
    "\n",
    "    # Create subplots\n",
    "    plt.rcParams['font.size'] = 18\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(22, 5))\n",
    "    for ax,it in zip(axs,range(3)):\n",
    "        # Creating x vector. (Time)\n",
    "        vec_length = Neuron_data[it].shape[0]\n",
    "        temp_vec = np.linspace(0,vec_length,vec_length)*0.02\n",
    "        \n",
    "        # Creating the areas for each trial\n",
    "        #Wheel Stop\n",
    "        #Sections Cue\n",
    "        ini_stop = np.where(np.diff(Input_data[it][:,0])==1.)[0]-50\n",
    "        end_stop = np.where(np.diff(Input_data[it][:,0])==1.)[0]\n",
    "        stop_sections = [(ini_stop[i]*0.02,end_stop[i]*0.02) for i in range(len(ini_stop))]\n",
    "        #Sections Cue\n",
    "        ini_cue = np.where(np.diff(Input_data[it][:,0])==1.)[0]+1\n",
    "        end_cue = np.where(np.diff(Input_data[it][:,0])==-1.)[0]+1\n",
    "        cue_sections = [(ini_cue[i]*0.02,end_cue[i]*0.02) for i in range(len(ini_cue))]\n",
    "        #Sections Reward Gamble\n",
    "        ini_grew = np.where(np.diff(Input_data[it][:,1])==4.)[0]+1\n",
    "        end_grew = np.where(np.diff(Input_data[it][:,1])==-4.)[0]+1+25\n",
    "        grew_sections = [(ini_grew[i]*0.02,end_grew[i]*0.02) for i in range(len(ini_grew))]\n",
    "        #Sections Reward Safe\n",
    "        ini_srew = np.where(np.diff(Input_data[it][:,2])==1.)[0]+1\n",
    "        end_srew = np.where(np.diff(Input_data[it][:,2])==-1.)[0]+1+25\n",
    "        srew_sections = [(ini_srew[i]*0.02,end_srew[i]*0.02) for i in range(len(ini_srew))]\n",
    "\n",
    "        # Ploting the data for each concatenated trial\n",
    "        ax.plot(temp_vec,Neuron_data[it][:,eneu],color=c_recorded_activity, lw = 2,label=\"Recorded activity\")\n",
    "        ax.plot(temp_vec,Model_data[it][:,eneu],color=c_simulated_activity, lw = 2,label=\"Simulated activity\")\n",
    "        for section in stop_sections:\n",
    "            start, end = section\n",
    "            ax.add_patch(Rectangle((start, ax.get_ylim()[0]), end - start, ax.get_ylim()[1]-ax.get_ylim()[0], color=c_stop, alpha=alpha_value))\n",
    "        for section in cue_sections:\n",
    "            start, end = section\n",
    "            ax.add_patch(Rectangle((start, ax.get_ylim()[0]), end - start, ax.get_ylim()[1]-ax.get_ylim()[0], color=c_cue, alpha=alpha_value))\n",
    "        for section in grew_sections:\n",
    "            start, end = section\n",
    "            ax.add_patch(Rectangle((start, ax.get_ylim()[0]), end - start, ax.get_ylim()[1]-ax.get_ylim()[0], color=c_gamble, alpha=alpha_value))\n",
    "        for section in srew_sections:\n",
    "            start, end = section\n",
    "            ax.add_patch(Rectangle((start, ax.get_ylim()[0]), end - start, ax.get_ylim()[1]-ax.get_ylim()[0], color=c_safe, alpha=alpha_value))\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Firing rate (norm.)\")\n",
    "    # Add legend outside the subplots\n",
    "    handles, labels = axs[0].get_legend_handles_labels()\n",
    "    rect_handles = [\n",
    "        Line2D([0], [0], color=c_stop, alpha=alpha_value, lw=12, label='Stop'),\n",
    "        Line2D([0], [0], color=c_cue, alpha=alpha_value, lw=12, label='Cue'),\n",
    "        Line2D([0], [0], color=c_gamble, alpha=alpha_value, lw=12, label='Grew'),\n",
    "        Line2D([0], [0], color=c_safe, alpha=alpha_value, lw=12, label='Srew')\n",
    "    ]\n",
    "    fig.legend(handles=handles + rect_handles, labels=labels + ['Wheel stop','Response phase','Gamble reward','Safe reward'], \n",
    "            loc='upper center', bbox_to_anchor=(0.5, 1.2), ncol=6, fontsize = 22)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "######################\n",
    "def Classifier_Test_Sessions(data_path,mpath,behaviour_path,num_epochs):\n",
    "\n",
    "    # Selection of the file\n",
    "    os.chdir(behaviour_path)\n",
    "    list_files = os.listdir(behaviour_path)\n",
    "    for i in list_files:\n",
    "        if i.find('Behaviour')>0:\n",
    "            Behaviour_name = i\n",
    "\n",
    "    # Load data\n",
    "    # Open the Behaviour file\n",
    "    Bdata = scipy.io.loadmat(Behaviour_name)\n",
    "    BehData = Bdata[list(Bdata.keys())[-1]]\n",
    "\n",
    "    # Next Decision (G,S)\n",
    "    ND = (BehData[:,12]==1)*1+(BehData[:,12]==0)*0\n",
    "\n",
    "    # Reward (Gamble, Safe, Nothing)\n",
    "    RW = (BehData[:,12]==1)*(BehData[:,13])*2+(BehData[:,13])*(BehData[:,12]==0)*1\n",
    "\n",
    "    # Blocks (High, Medium, Low)\n",
    "    blocks=np.unique(BehData[:,5])\n",
    "    if len(blocks)==3:\n",
    "        B_se=(BehData[:,5]==blocks[0])*0+(BehData[:,5]==blocks[1])*1+(BehData[:,5]==blocks[2])*2\n",
    "    elif len(blocks)==2:\n",
    "        B_se=(BehData[:,5]==blocks[0])*0+(BehData[:,5]==blocks[1])*1\n",
    "    elif len(blocks)<2:\n",
    "        print(\"There is no different blocks to classify the data\")\n",
    "    else:\n",
    "        print(\"This is not the original task\")\n",
    "\n",
    "    train_n,train_i = func.load_data(data_path,'Training')\n",
    "\n",
    "    Hyper_mod(mpath,data_path)\n",
    "\n",
    "    # Loading Model\n",
    "    m = Model()\n",
    "    m.init_from_model_path(mpath, epoch=num_epochs)\n",
    "    m.eval()\n",
    "\n",
    "    # Generation Training Data\n",
    "    ModelS=[]\n",
    "    for w_index in tqdm(range(len(train_n))):\n",
    "        data_trial=tc.from_numpy(train_n[w_index]).float()          # tensor of neuronal data for initial trial data\n",
    "        input_trial = tc.from_numpy(train_i[w_index]).float()\n",
    "        length_sim = input_trial.shape[0]\n",
    "        X, _ = m.generate_free_trajectory(data_trial,input_trial,length_sim,w_index)\n",
    "        ModelS.append(X[:,:])\n",
    "\n",
    "    # Concatenating signals\n",
    "    Nseries,_=func.concatenate_list(train_n,0)          # recorded activity\n",
    "    Iseries,_=func.concatenate_list(train_i,0)          # external input\n",
    "    Mseries,_=func.concatenate_list(ModelS,0)           # simulated activity\n",
    "\n",
    "\n",
    "    # Second point:\n",
    "    # Load Metadata\n",
    "    file=open(os.path.join(data_path,'Metadata.pkl'),'rb')\n",
    "    Metadata=pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    test_n,test_i = func.load_data(data_path,'Test')\n",
    "\n",
    "    # Obtaining the original data for test trials and geneterate test trials by the model\n",
    "    _, W1t, W2t, _, _, Ct = m.get_latent_parameters()\n",
    "\n",
    "    # Transform tensor to numpy format\n",
    "    W2 = W2t.detach().numpy().transpose(1,2,0)\n",
    "    W1 = W1t.detach().numpy().transpose(1,2,0)\n",
    "    C = Ct.detach().numpy()\n",
    "    # General Parameters\n",
    "    num_neurons=train_n[0].shape[1]\n",
    "\n",
    "    # Generate Latent states for Test Trials\n",
    "    # Identificating Test Trials in the training trial set\n",
    "    t_prev = [i for i in Metadata[\"Training2Test\"]]\n",
    "    t_post = [i+1 for i in Metadata[\"Training2Test\"]]\n",
    "\n",
    "    # Computing W matrices for test trials\n",
    "    W2_test = np.empty((W2.shape[0],W2.shape[1],len(Metadata[\"TestTrials\"])))\n",
    "    W1_test = np.empty((W1.shape[0],W1.shape[1],len(Metadata[\"TestTrials\"])))\n",
    "    for i in range(len(t_prev)):\n",
    "        W2_test[:,:,i] = (W2[:,:,t_prev[i]]+W2[:,:,t_post[i]])/2.0\n",
    "        W1_test[:,:,i] = (W1[:,:,t_prev[i]]+W1[:,:,t_post[i]])/2.0\n",
    "    #Generate Latent states\n",
    "    ModelT = []\n",
    "\n",
    "    #Generate Latent states\n",
    "    W1_ind = [tc.from_numpy(W1_test[:,:,i]).float() for i in range(len(t_prev))]\n",
    "    W2_ind = [tc.from_numpy(W2_test[:,:,i]).float() for i in range(len(t_prev))]\n",
    "    for i in range(len(W1_ind)):\n",
    "        data_test=tc.from_numpy(test_n[i]).float()\n",
    "        input_test=tc.from_numpy(test_i[i]).float()\n",
    "        T0=test_n[i].shape[0]\n",
    "        X, _ = m.generate_test_trajectory(data_test[0:11,:],W2_ind[i],W1_ind[i],input_test, T0,i)\n",
    "        ModelT.append(X)\n",
    "\n",
    "    neuron_example = 36\n",
    "    Plot_trace_example(test_n,ModelT,test_i,neuron_example)\n",
    "\n",
    "    # Concatenating signals\n",
    "    IseriesT,_=func.concatenate_list(test_i,0)          # external input\n",
    "    MseriesT,_=func.concatenate_list(ModelT,0)           # simulated activity\n",
    "    NseriesT,_=func.concatenate_list(test_n,0)\n",
    "\n",
    "    Test_trials = Metadata[\"TestTrials\"]; Training_trials = Metadata[\"TrainingTrials\"]    \n",
    "        \n",
    "    itrain = 0\n",
    "    itest = 0\n",
    "    Trials_inmodel = []\n",
    "\n",
    "    for i in range(len(Metadata[\"TestTrials\"])+len(Metadata[\"TrainingTrials\"])):\n",
    "        if i in Metadata[\"TrainingTrials\"]:\n",
    "            Trials_inmodel.append(np.sum(np.diff(train_i[itrain][:,0])==1))\n",
    "            itrain += 1\n",
    "        elif i in Metadata[\"TestTrials\"]:\n",
    "            Trials_inmodel.append(np.sum(np.diff(test_i[itest][:,0])==1))\n",
    "            itest += 1\n",
    "            \n",
    "    # Cumulative sum of the behavioural trials in concatenated trials        \n",
    "    CUM_trials = [int(np.sum(Trials_inmodel[:i])) for i in range(len(Trials_inmodel)+1)]\n",
    "\n",
    "    trials_test = []\n",
    "    for k in range(len(Test_trials)):    \n",
    "        trials_test = trials_test+[i for i in range(CUM_trials[Test_trials[k]],CUM_trials[Test_trials[k]+1])]\n",
    "\n",
    "    trials_train = []\n",
    "    for k in range(len(Training_trials)):\n",
    "        trials_train = trials_train+[i for i in range(CUM_trials[Training_trials[k]],CUM_trials[Training_trials[k]+1])]\n",
    "\n",
    "    # Choice Prediction\n",
    "    # Temporal sectors\n",
    "    CueTime_end = np.where(np.diff(Iseries[:,0])==-1)[0]\n",
    "    StopTime = np.where(np.diff(Iseries[:,0])==1)[0]-49\n",
    "    # Data Set Mean Activity Zscore Neurons\n",
    "    num_trials = len(CueTime_end)\n",
    "    num_neurons = Nseries.shape[1]\n",
    "    Neural_train = np.zeros((num_trials,num_neurons))\n",
    "    Model_train = np.zeros((num_trials,num_neurons))\n",
    "    for it in range(num_trials):\n",
    "        Neural_train[it,:]=np.mean(Nseries[StopTime[it]:CueTime_end[it],:],0)\n",
    "        Model_train[it,:]=np.mean(Mseries[StopTime[it]:CueTime_end[it],:],0)\n",
    "\n",
    "\n",
    "    # Temporal sectors\n",
    "    CueTime_endT = np.where(np.diff(IseriesT[:,0])==-1)[0]\n",
    "    StopTimeT = np.where(np.diff(IseriesT[:,0])==1)[0]-49\n",
    "    # Data Set Mean Activity Zscore Neurons\n",
    "    num_trialsT = len(CueTime_endT)\n",
    "    num_neuronsT = MseriesT.shape[1]\n",
    "    Neural_test = np.zeros((num_trialsT,num_neuronsT))\n",
    "    Model_test = np.zeros((num_trialsT,num_neuronsT))\n",
    "    for it in range(num_trialsT):\n",
    "        Neural_test[it,:]=np.mean(NseriesT[StopTimeT[it]:CueTime_endT[it],:],0)\n",
    "        Model_test[it,:]=np.mean(MseriesT[StopTimeT[it]:CueTime_endT[it],:],0)\n",
    "\n",
    "    C_data,_,C_model,_ = Classifier_events(Neural_train,Neural_test,Model_train,Model_test,ND,trials_train,trials_test)\n",
    "\n",
    "\n",
    "    # Reward Prediction\n",
    "    # Temporal sectors\n",
    "    RewTime_ini = np.where(np.diff(Iseries[:,0])==-1)[0]\n",
    "    RT_end = np.where(np.diff(Iseries[:,0])==1)[0]-49\n",
    "    RewTime_end = np.append(RT_end[1:],Iseries.shape[0])\n",
    "    # Data Set Mean Activity Zscore Neurons\n",
    "    num_trials = len(CueTime_end)\n",
    "    num_neurons = Nseries.shape[1]\n",
    "    Neural_train = np.zeros((num_trials,num_neurons))\n",
    "    Model_train = np.zeros((num_trials,num_neurons))\n",
    "    for it in range(num_trials):\n",
    "        Neural_train[it,:]=np.mean(Nseries[RewTime_ini[it]:RewTime_end[it],:],0)\n",
    "        Model_train[it,:]=np.mean(Mseries[RewTime_ini[it]:RewTime_end[it],:],0)\n",
    "\n",
    "\n",
    "    # Temporal sectors\n",
    "    RewTime_iniT = np.where(np.diff(IseriesT[:,0])==-1)[0]\n",
    "    RT_endT = np.where(np.diff(IseriesT[:,0])==1)[0]-49\n",
    "    RewTime_endT = np.append(RT_endT[1:],IseriesT.shape[0])\n",
    "    # Data Set Mean Activity Zscore Neurons\n",
    "    num_trialsT = len(CueTime_endT)\n",
    "    num_neuronsT = MseriesT.shape[1]\n",
    "    Neural_test = np.zeros((num_trialsT,num_neuronsT))\n",
    "    Model_test = np.zeros((num_trialsT,num_neuronsT))\n",
    "    for it in range(num_trialsT):\n",
    "        Neural_test[it,:]=np.mean(NseriesT[RewTime_iniT[it]:RewTime_endT[it],:],0)\n",
    "        Model_test[it,:]=np.mean(MseriesT[RewTime_iniT[it]:RewTime_endT[it],:],0)\n",
    "\n",
    "    R_data,_,R_model,_ = Classifier_events(Neural_train,Neural_test,Model_train,Model_test,RW,trials_train,trials_test)\n",
    "\n",
    "    #Block Prediction\n",
    "    # Temporal sectors\n",
    "    TrialTime_ini = np.where(np.diff(Iseries[:,0])==1)[0]-49\n",
    "    TrialTime_end = np.append(TrialTime_ini[1:],Iseries.shape[0])\n",
    "    # Data Set Mean Activity Zscore Neurons\n",
    "    num_trials = len(CueTime_end)\n",
    "    num_neurons = Nseries.shape[1]\n",
    "    Neural_train = np.zeros((num_trials,num_neurons))\n",
    "    Model_train = np.zeros((num_trials,num_neurons))\n",
    "    for it in range(num_trials):\n",
    "        Neural_train[it,:]=np.mean(Nseries[TrialTime_ini[it]:TrialTime_end[it],:],0)\n",
    "        Model_train[it,:]=np.mean(Mseries[TrialTime_ini[it]:TrialTime_end[it],:],0)\n",
    "\n",
    "    # Temporal sectors\n",
    "    TrialTime_iniT = np.where(np.diff(IseriesT[:,0])==1)[0]-49\n",
    "    TrialTime_endT = np.append(TrialTime_iniT[1:],IseriesT.shape[0])\n",
    "    # Data Set Mean Activity Zscore Neurons\n",
    "    num_trialsT = len(CueTime_endT)\n",
    "    num_neuronsT = MseriesT.shape[1]\n",
    "    Neural_test = np.zeros((num_trialsT,num_neuronsT))\n",
    "    Model_test = np.zeros((num_trialsT,num_neuronsT))\n",
    "    for it in range(num_trialsT):\n",
    "        Neural_test[it,:]=np.mean(NseriesT[TrialTime_iniT[it]:TrialTime_endT[it],:],0)\n",
    "        Model_test[it,:]=np.mean(MseriesT[TrialTime_iniT[it]:TrialTime_endT[it],:],0)\n",
    "\n",
    "    B_data,_,B_model,_ = Classifier_events(Neural_train,Neural_test,Model_train,Model_test,B_se,trials_train,trials_test)\n",
    "\n",
    "    return C_data,C_model,R_data,R_model,B_data,B_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a5fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data Organization\n",
    "# General Directories\n",
    "path_models = 'D:\\\\_work_cestarellas\\\\Analysis\\\\Pack_Daniel_project\\\\Preprocess_model\\\\' # For models and Training and Test data\n",
    "path_behaviours = 'D:\\\\_work_cestarellas\\\\Analysis\\\\PLRNN\\\\Session_Selected\\\\OFC'        # For behavioural sessions\n",
    "\n",
    "#Model\n",
    "mod_sessions = os.listdir(path_models)\n",
    "extra_models = 'results\\\\DataTrainingH768_lm1_1e-05_lm2_128_lm3_00_seql_400\\\\001'\n",
    "#Neuronal Activity\n",
    "extra_activity = 'neuralactivity\\\\datasets\\\\'\n",
    "#Behaviour\n",
    "rec_sessions = os.listdir(path_behaviours)\n",
    "\n",
    "#################### WARNING\n",
    "# Be careful!!! Check if the order of mod_sessions and rec_sessions is the same\n",
    "#################### WARNING\n",
    "print(mod_sessions)\n",
    "print(rec_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcdc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sessions = len(mod_sessions)\n",
    "last_epoch = 150000\n",
    "Choice_rec = [] ; Choice_gen =[]\n",
    "Reward_rec = [] ; Reward_gen =[]\n",
    "Block_rec = [] ; Block_gen =[]\n",
    "\n",
    "\n",
    "for isess in range(num_sessions):\n",
    "    Neural_path = os.path.join(path_models,mod_sessions[isess],extra_activity)\n",
    "    Model_path = os.path.join(path_models,mod_sessions[isess],extra_models).replace('\\\\','/')\n",
    "    Behavioural_path = os.path.join(path_behaviours,rec_sessions[isess]).replace('\\\\','/')\n",
    "    Hyper_mod(Model_path,Neural_path)\n",
    "    C_data,C_model,R_data,R_model,B_data,B_model = Classifier_Test_Sessions(Neural_path,Model_path,Behavioural_path,last_epoch)\n",
    "    Choice_rec.append(C_data) ; Choice_gen.append(C_model)\n",
    "    Reward_rec.append(R_data) ; Reward_gen.append(R_model)\n",
    "    Block_rec.append(B_data) ; Block_gen.append(B_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PLAna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
